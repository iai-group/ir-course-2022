{"cells":[{"cell_type":"markdown","metadata":{"id":"HWQgIBxfXyzM"},"source":["# Bigram matches in Elasticsearch\n","\n","This exercise is about getting ordered and unordered bigram matches using Elasticsearch."]},{"cell_type":"code","source":["!pip install ipytest"],"metadata":{"id":"b4P727p0YvXo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663231321444,"user_tz":-120,"elapsed":11988,"user":{"displayName":"Nolwenn Bernard","userId":"02479635665654727159"}},"outputId":"109bfac6-9b56-4440-de69-b81c3b61f053"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ipytest\n","  Downloading ipytest-0.12.0-py3-none-any.whl (15 kB)\n","Collecting pytest>=5.4\n","  Downloading pytest-7.1.3-py3-none-any.whl (298 kB)\n","\u001b[K     |████████████████████████████████| 298 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ipytest) (21.3)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipytest) (7.9.0)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (22.1.0)\n","Collecting iniconfig\n","  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n","Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (1.11.0)\n","Collecting pluggy<2.0,>=0.12\n","  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (4.12.0)\n","Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (2.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=5.4->ipytest) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=5.4->ipytest) (3.8.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (4.8.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (5.1.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (2.6.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.2.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.7.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (57.4.0)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (2.0.10)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 32.3 MB/s \n","\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->ipytest) (0.8.3)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipytest) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipytest) (0.2.5)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->ipytest) (3.0.9)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipytest) (0.7.0)\n","Installing collected packages: pluggy, jedi, iniconfig, pytest, ipytest\n","  Attempting uninstall: pluggy\n","    Found existing installation: pluggy 0.7.1\n","    Uninstalling pluggy-0.7.1:\n","      Successfully uninstalled pluggy-0.7.1\n","  Attempting uninstall: pytest\n","    Found existing installation: pytest 3.6.4\n","    Uninstalling pytest-3.6.4:\n","      Successfully uninstalled pytest-3.6.4\n","Successfully installed iniconfig-1.1.1 ipytest-0.12.0 jedi-0.18.1 pluggy-1.0.0 pytest-7.1.3\n"]}]},{"cell_type":"code","source":["!pip install elasticsearch==7.9.0"],"metadata":{"id":"UF8_be86YyBJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663231326845,"user_tz":-120,"elapsed":5415,"user":{"displayName":"Nolwenn Bernard","userId":"02479635665654727159"}},"outputId":"6ee9fcd6-5a66-4739-ebba-062f65c530dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting elasticsearch==7.9.0\n","  Downloading elasticsearch-7.9.0-py2.py3-none-any.whl (213 kB)\n","\u001b[K     |████████████████████████████████| 213 kB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch==7.9.0) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch==7.9.0) (2022.6.15)\n","Installing collected packages: elasticsearch\n","Successfully installed elasticsearch-7.9.0\n"]}]},{"cell_type":"code","source":["%%bash\n","\n","wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz\n","wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512\n","tar -xzf elasticsearch-oss-7.9.2-linux-x86_64.tar.gz\n","sudo chown -R daemon:daemon elasticsearch-7.9.2/\n","shasum -a 512 -c elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512 "],"metadata":{"id":"fl8ghWrbdrTJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663231374499,"user_tz":-120,"elapsed":47671,"user":{"displayName":"Nolwenn Bernard","userId":"02479635665654727159"}},"outputId":"dc3efebd-2b96-43ee-a6cc-0049192d77dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["elasticsearch-oss-7.9.2-linux-x86_64.tar.gz: OK\n"]}]},{"cell_type":"code","source":["%%bash --bg\n","\n","sudo -H -u daemon elasticsearch-7.9.2/bin/elasticsearch"],"metadata":{"id":"1eP24fq7dwpA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sleep for few seconds to let the instance start.\n","import time\n","time.sleep(20)"],"metadata":{"id":"twQRaoCedyYW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","\n","ps -ef | grep elasticsearch"],"metadata":{"id":"dlUnRTAFd4uX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663231394691,"user_tz":-120,"elapsed":48,"user":{"displayName":"Nolwenn Bernard","userId":"02479635665654727159"}},"outputId":"f2fb58f6-237f-44d1-a8d3-625dabe5f130"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root         168     166  0 08:42 ?        00:00:00 sudo -H -u daemon elasticsearch-7.9.2/bin/elasticsearch\n","daemon       169     168 99 08:42 ?        00:00:20 /content/elasticsearch-7.9.2/jdk/bin/java -Xshare:auto -Des.networkaddress.cache.ttl=60 -Des.networkaddress.cache.negative.ttl=10 -XX:+AlwaysPreTouch -Xss1m -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -XX:-OmitStackTraceInFastThrow -XX:+ShowCodeDetailsInExceptionMessages -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 -Dio.netty.allocator.numDirectArenas=0 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.locale.providers=SPI,COMPAT -Xms1g -Xmx1g -XX:+UseG1GC -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -Djava.io.tmpdir=/tmp/elasticsearch-7080371589566594553 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=data -XX:ErrorFile=logs/hs_err_pid%p.log -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m -XX:MaxDirectMemorySize=536870912 -Des.path.home=/content/elasticsearch-7.9.2 -Des.path.conf=/content/elasticsearch-7.9.2/config -Des.distribution.flavor=oss -Des.distribution.type=tar -Des.bundled_jdk=true -cp /content/elasticsearch-7.9.2/lib/* org.elasticsearch.bootstrap.Elasticsearch\n","root         413     411  0 08:43 ?        00:00:00 grep elasticsearch\n"]}]},{"cell_type":"code","source":["%%bash\n","\n","curl -sX GET \"localhost:9200/\""],"metadata":{"id":"8oBRxkdpd64Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663231394692,"user_tz":-120,"elapsed":27,"user":{"displayName":"Nolwenn Bernard","userId":"02479635665654727159"}},"outputId":"5d80d8e7-f8f5-4894-b1c5-35898a7ab21a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"name\" : \"449c557fdc0b\",\n","  \"cluster_name\" : \"elasticsearch\",\n","  \"cluster_uuid\" : \"VkbUjcNeQ7-fcKUWfXBlXA\",\n","  \"version\" : {\n","    \"number\" : \"7.9.2\",\n","    \"build_flavor\" : \"oss\",\n","    \"build_type\" : \"tar\",\n","    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n","    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n","    \"build_snapshot\" : false,\n","    \"lucene_version\" : \"8.6.2\",\n","    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n","    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n","  },\n","  \"tagline\" : \"You Know, for Search\"\n","}\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LR5PftFXXyzN"},"outputs":[],"source":["from collections import Counter\n","from elasticsearch import Elasticsearch\n","from pprint import pprint\n","\n","import ipytest\n","import pytest\n","\n","ipytest.autoconfig()"]},{"cell_type":"markdown","metadata":{"id":"UGHBzBQNXyzN"},"source":["## Indexing a toy collection \n","\n","This time, we store **term position information** and perform minimal stemming, i.e., removing only plurals (for that, we specify a custom analyzer).\n","\n","Check the [Elasticsearch documentation on analyzers](https://www.elastic.co/guide/en/elasticsearch/reference/current/analyzer.html)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AvETQfFnXyzN"},"outputs":[],"source":["INDEX_NAME = \"toy_index\"  \n","\n","INDEX_SETTINGS = {\n","    'settings' : {\n","        'index' : {\n","            \"number_of_shards\" : 1,\n","            \"number_of_replicas\" : 1\n","        },\n","        'analysis': {\n","            'analyzer': {\n","                'my_english_analyzer': {\n","                    'type': \"custom\",\n","                    'tokenizer': \"standard\",\n","                    'stopwords': \"_english_\",\n","                    'filter': [\n","                        \"lowercase\",\n","                        \"english_stop\",\n","                        \"filter_english_minimal\"\n","                    ]                \n","                }\n","            },\n","            'filter' : {\n","                'filter_english_minimal' : {\n","                    'type': \"stemmer\",\n","                    'name': \"minimal_english\"\n","                },\n","                'english_stop': {\n","                    'type': \"stop\",\n","                    'stopwords': \"_english_\"\n","                }\n","            },\n","        }\n","    },\n","    'mappings': {\n","        'properties': {\n","            'title': {\n","                'type': \"text\",\n","                'term_vector': \"with_positions\",\n","                'analyzer': \"my_english_analyzer\"\n","            },\n","            'content': {\n","                'type': \"text\",\n","                'term_vector': \"with_positions\",\n","                'analyzer': \"my_english_analyzer\"\n","            }\n","        }\n","    }\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQvCcwDrXyzO"},"outputs":[],"source":["DOCS = {\n","    1: {\"title\": \"Rap God\",\n","        \"content\": \"gonna, gonna, Look, I was gonna go easy on you and not to hurt your feelings\"\n","        },\n","    2: {\"title\": \"Lose Yourself\",\n","        \"content\": \"Yo, if you could just, for one minute Or one split second in time, forget everything Everything that bothers you, or your problems Everything, and follow me\"\n","        },\n","    3: {\"title\": \"Love The Way You Lie\",\n","        \"content\": \"Just gonna stand there and watch me burn But that's alright, because I like the way it hurts\"\n","        },\n","    4: {\"title\": \"The Monster\",\n","        \"content\": [\"gonna gonna I'm friends with the monster\", \"That's under my bed Get along with the voices inside of my head\"]\n","        },\n","    5: {\"title\": \"Beautiful\",\n","        \"content\": \"Lately I've been hard to reach I've been too long on my own Everybody has a private world Where they can be alone\"\n","        },\n","    6: {\"title\": \"Fake Eminem 1\",\n","        \"content\": \"This is not real Eminem, just some text to get more matches for a split second for a split second.\"\n","        },\n","    7: {\"title\": \"Fake Eminem 2\",\n","        \"content\": \"I have a monster friend and I'm friends with the monster and then there are some more friends who are monsters.\"\n","        },\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kfPB4wdyXyzO"},"outputs":[],"source":["ES_NODES = \"http://localhost:9200\"\n","es = Elasticsearch(hosts = [ES_NODES])"]},{"cell_type":"code","source":["es.info()"],"metadata":{"id":"ozCr_Z1ehg23","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663231395265,"user_tz":-120,"elapsed":10,"user":{"displayName":"Nolwenn Bernard","userId":"02479635665654727159"}},"outputId":"193b42dd-89fe-4cb1-a1bf-7bf348651114"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'name': '449c557fdc0b',\n"," 'cluster_name': 'elasticsearch',\n"," 'cluster_uuid': 'VkbUjcNeQ7-fcKUWfXBlXA',\n"," 'version': {'number': '7.9.2',\n","  'build_flavor': 'oss',\n","  'build_type': 'tar',\n","  'build_hash': 'd34da0ea4a966c4e49417f2da2f244e3e97b4e6e',\n","  'build_date': '2020-09-23T00:45:33.626720Z',\n","  'build_snapshot': False,\n","  'lucene_version': '8.6.2',\n","  'minimum_wire_compatibility_version': '6.8.0',\n","  'minimum_index_compatibility_version': '6.0.0-beta1'},\n"," 'tagline': 'You Know, for Search'}"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZgYzlrcrXyzO"},"outputs":[],"source":["if es.indices.exists(index=INDEX_NAME):\n","    es.indices.delete(index=INDEX_NAME)"]},{"cell_type":"code","source":["es.indices.create(index=INDEX_NAME, body=INDEX_SETTINGS)"],"metadata":{"id":"ILV1N_6aer2d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663231396213,"user_tz":-120,"elapsed":954,"user":{"displayName":"Nolwenn Bernard","userId":"02479635665654727159"}},"outputId":"5cd4aabd-fc7c-4017-ef0e-6ed75679b4f1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'acknowledged': True, 'shards_acknowledged': True, 'index': 'toy_index'}"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"KHHE6EqbXyzP"},"source":["Testing our analyzer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rmb5UUaOXyzP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663231396213,"user_tz":-120,"elapsed":9,"user":{"displayName":"Nolwenn Bernard","userId":"02479635665654727159"}},"outputId":"f4683506-4e57-4303-f28a-cea8f07b7efc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'tokens': [{'token': 'monster',\n","   'start_offset': 0,\n","   'end_offset': 8,\n","   'type': '<ALPHANUM>',\n","   'position': 0},\n","  {'token': 'my',\n","   'start_offset': 12,\n","   'end_offset': 14,\n","   'type': '<ALPHANUM>',\n","   'position': 2},\n","  {'token': 'bed',\n","   'start_offset': 15,\n","   'end_offset': 18,\n","   'type': '<ALPHANUM>',\n","   'position': 3}]}"]},"metadata":{},"execution_count":15}],"source":["es.indices.analyze(index=INDEX_NAME, body={'analyzer': 'my_english_analyzer', 'text': 'monsters in my bed'})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GaXc0R7pXyzP"},"outputs":[],"source":["for doc_id, doc in DOCS.items():\n","    es.index(index=INDEX_NAME, id=doc_id, body=doc)"]},{"cell_type":"markdown","metadata":{"id":"u-kQL4WpXyzP"},"source":["Notice that you also get term position information when requesting a term vector."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQJXKCQRXyzP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663231397027,"user_tz":-120,"elapsed":817,"user":{"displayName":"Nolwenn Bernard","userId":"02479635665654727159"}},"outputId":"b769520c-c548-4085-87ab-be73069dccd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'_id': '2',\n"," '_index': 'toy_index',\n"," '_type': '_doc',\n"," '_version': 1,\n"," 'found': True,\n"," 'term_vectors': {'content': {'field_statistics': {'doc_count': 7,\n","                                                   'sum_doc_freq': 85,\n","                                                   'sum_ttf': 101},\n","                              'terms': {'bother': {'term_freq': 1,\n","                                                   'tokens': [{'position': 18}]},\n","                                        'could': {'term_freq': 1,\n","                                                  'tokens': [{'position': 3}]},\n","                                        'everything': {'term_freq': 3,\n","                                                       'tokens': [{'position': 15},\n","                                                                  {'position': 16},\n","                                                                  {'position': 23}]},\n","                                        'follow': {'term_freq': 1,\n","                                                   'tokens': [{'position': 25}]},\n","                                        'forget': {'term_freq': 1,\n","                                                   'tokens': [{'position': 14}]},\n","                                        'just': {'term_freq': 1,\n","                                                 'tokens': [{'position': 4}]},\n","                                        'me': {'term_freq': 1,\n","                                               'tokens': [{'position': 26}]},\n","                                        'minute': {'term_freq': 1,\n","                                                   'tokens': [{'position': 7}]},\n","                                        'one': {'term_freq': 2,\n","                                                'tokens': [{'position': 6},\n","                                                           {'position': 9}]},\n","                                        'problem': {'term_freq': 1,\n","                                                    'tokens': [{'position': 22}]},\n","                                        'second': {'term_freq': 1,\n","                                                   'tokens': [{'position': 11}]},\n","                                        'split': {'term_freq': 1,\n","                                                  'tokens': [{'position': 10}]},\n","                                        'time': {'term_freq': 1,\n","                                                 'tokens': [{'position': 13}]},\n","                                        'yo': {'term_freq': 1,\n","                                               'tokens': [{'position': 0}]},\n","                                        'you': {'term_freq': 2,\n","                                                'tokens': [{'position': 2},\n","                                                           {'position': 19}]},\n","                                        'your': {'term_freq': 1,\n","                                                 'tokens': [{'position': 21}]}}},\n","                  'title': {'field_statistics': {'doc_count': 7,\n","                                                 'sum_doc_freq': 16,\n","                                                 'sum_ttf': 16},\n","                            'terms': {'lose': {'term_freq': 1,\n","                                               'tokens': [{'position': 0}]},\n","                                      'yourself': {'term_freq': 1,\n","                                                   'tokens': [{'position': 1}]}}}},\n"," 'took': 90}\n"]}],"source":["tv = es.termvectors(index=INDEX_NAME, id=2, fields='title,content')\n","pprint(tv)"]},{"cell_type":"markdown","metadata":{"id":"aaCY3YwyXyzP"},"source":["## Recovering ordered sequence of terms from inverted index\n","\n","This method returns the sequence of terms for a given document field, with `None` values for stopwords that got removed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zr0L-mPHXyzQ"},"outputs":[],"source":["def get_term_sequence(es, doc_id, field):\n","    tv = es.termvectors(index=INDEX_NAME, id=doc_id, fields=[field])\n","    # We first put terms in a position-indexed dict.\n","    pos = {}\n","    for term, tinfo in tv['term_vectors'][field]['terms'].items():\n","        for token in tinfo['tokens']:\n","            pos[token['position']] = term\n","    # Then, turn that dict to a list.\n","    seq = [None] * (max(pos.keys()) + 1)\n","    for p, term in pos.items():\n","        seq[p] = term\n","    return seq"]},{"cell_type":"markdown","metadata":{"id":"tEV_0i6YXyzQ"},"source":["Tests."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bwWlKt5nXyzQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663231397028,"user_tz":-120,"elapsed":20,"user":{"displayName":"Nolwenn Bernard","userId":"02479635665654727159"}},"outputId":"88b3d0de-55db-4036-e625-b6bf38d04de4"},"outputs":[{"output_type":"stream","name":"stderr","text":["%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n","\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[0m\n"]}],"source":["%%run_pytest[clean]\n","\n","def test_get_term_sequence():\n","    assert get_term_sequence(es, 4, 'title') == [None, 'monster']\n","    assert get_term_sequence(es, 7, 'content') == ['i', 'have', None, 'monster', 'friend', None, \"i'm\", 'friend', None, None, 'monster', None, None, None, None, 'some', 'more', 'friend', 'who', None, 'monster']"]},{"cell_type":"markdown","metadata":{"id":"o_nG_1EUXyzQ"},"source":["## Getting ordered bigram matches\n","\n","Use the `get_term_sequence()` method to get the document field's content as a sequence of terms, then check for ordered bigram matches yourself."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7Q20RIdXyzQ"},"outputs":[],"source":["def count_ordered_bigram_matches(es, doc_id, field, bigram):\n","    \"\"\"Counts the number of ordered bigram matches in a given document field. \n","    \n","    Args:\n","        es: Elasticsearch instance\n","        doc_id: Document ID\n","        field: Document field\n","        bigram: A sequence of two terms given as a list\n","    \n","    Returns:\n","        Number of times the bigram can be found in this exact order.\n","    \"\"\"\n","    # Get the document field's content as a sequence of terms.\n","    text = get_term_sequence(es, doc_id, field)\n","    # Count the number of matches    \n","    count = 0\n","    for i in range(len(text) - 1):\n","        if text[i] == bigram[0]:\n","            if text[i + 1] == bigram[1]:\n","                count += 1\n","    return count"]},{"cell_type":"markdown","metadata":{"id":"eko0CqLfXyzQ"},"source":["Tests."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m3AfABhmXyzQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663231397028,"user_tz":-120,"elapsed":13,"user":{"displayName":"Nolwenn Bernard","userId":"02479635665654727159"}},"outputId":"18221a77-4f98-4c2f-cfac-3d2163178968"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                          [100%]\u001b[0m\n","\u001b[32m\u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.04s\u001b[0m\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"]}],"source":["%%run_pytest[clean]\n","\n","@pytest.mark.parametrize('doc_id, field, bigram, correct_value', [\n","    (6, 'content', ['split', 'second'], 2),\n","    (2, 'content', ['split', 'second'], 1),\n","    (1, 'content', ['split', 'second'], 0),\n","])\n","def test_count_ordered_bigram_matches(doc_id, field, bigram, correct_value):\n","    assert count_ordered_bigram_matches(es, doc_id, field, bigram) == correct_value"]},{"cell_type":"markdown","metadata":{"id":"AiFiq-9JXyzQ"},"source":["## Getting unordered bigram matches\n","\n","As before, use the `get_term_sequence()` method to get the document field's content as a sequence of terms, then check for ordered bigram matches yourself."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X0NKDqCpXyzQ"},"outputs":[],"source":["def count_unordered_bigram_matches(es, doc_id, field, bigram, w=4):\n","    \"\"\"Counts the number of unordered bigram matches in a given document field. \n","    \n","    Args:\n","        es: Elasticsearch instance\n","        doc_id: Document ID\n","        field: Document field\n","        bigram: A sequence of two terms given as a list\n","        w: The maximum distance between the two query terms that still counts as a match\n","    \n","    Returns:\n","        Number of times the bigram can be found within a distance of w from each other in any order.\n","    \"\"\"\n","    text = get_term_sequence(es, doc_id, \"content\")\n","    count = 0\n","    for i in range(len(text) - 1):\n","        if text[i] in bigram:\n","            other_term = bigram[0] if text[i] == bigram[1] else bigram[1]\n","            count += Counter(text[i+1:i+w])[other_term]\n","    return count"]},{"cell_type":"markdown","metadata":{"id":"RKnWleAUXyzR"},"source":["Tests."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-2SygNxXyzR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663231397029,"user_tz":-120,"elapsed":9,"user":{"displayName":"Nolwenn Bernard","userId":"02479635665654727159"}},"outputId":"9a9b3f48-d190-4092-89fb-08a516ec9528"},"outputs":[{"output_type":"stream","name":"stderr","text":["%%run_pytest[clean] and %%run_pytest are deprecated in favor of %%ipytest. %%ipytest will clean tests, evaluate the cell and then run pytest. To disable cleaning, configure ipytest with ipytest.config(clean=False).\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                          [100%]\u001b[0m\n","\u001b[32m\u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.06s\u001b[0m\u001b[0m\n"]}],"source":["%%run_pytest[clean]\n","\n","@pytest.mark.parametrize('doc_id, field, bigram, correct_value', [\n","    (7, 'title', ['friend', 'monster'], 3),\n","    (4, 'title', ['friend', 'monster'], 1),\n","    (1, 'title', ['friend', 'monster'], 0),\n","])\n","def test_count_ordered_bigram_matches(doc_id, field, bigram, correct_value):\n","    assert count_unordered_bigram_matches(es, doc_id, field, bigram) == correct_value"]},{"cell_type":"markdown","metadata":{"id":"qFTW4AlUXyzR"},"source":["## Feedback\n","\n","Please give (anonymous) feedback on this exercise by filling out [this form](https://forms.gle/2jPayczbFhEcC9K68)."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}