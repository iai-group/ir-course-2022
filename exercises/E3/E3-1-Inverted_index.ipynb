{"cells":[{"cell_type":"markdown","metadata":{"id":"rL4_BaGE0zEv"},"source":["# Building an inverted index\n","\n","  - You are given a sample (1000 documents) from the [The Reuters-21578 data collection](http://www.daviddlewis.com/resources/testcollections/reuters21578/) in `data/reuters21578-000.xml`\n","  - The code that parses the XML and extract a list of preprocessed terms (tokenized, lowercased, stopwords removed) is already given\n","  - You are also given an `InvertedIndex` class that manages the posting lists operations\n","  - Your task is to build an inverted index from the input collection."]},{"cell_type":"code","source":["pip install ipytest"],"metadata":{"id":"L7G74gLV05oy"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJ76N1E_0zEy"},"outputs":[],"source":["import ipytest\n","import re\n","\n","from typing import List, Dict, Union, Any, Callable\n","from collections import Counter, defaultdict\n","from xml.dom import minidom\n","from dataclasses import dataclass\n","\n","ipytest.autoconfig()"]},{"cell_type":"markdown","metadata":{"id":"VbhPTOIs0zEz"},"source":["## Parsing documents"]},{"cell_type":"markdown","metadata":{"id":"5QB7FC-F0zEz"},"source":["Stopwords list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ibx30S7o0zEz"},"outputs":[],"source":["STOPWORDS = [\"a\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"by\", \"for\", \"if\", \"in\", \"into\", \"is\", \"it\", \"no\", \"not\", \"of\", \"on\", \"or\", \"such\", \"that\", \"the\", \"their\", \"then\", \"there\", \"these\", \"they\", \"this\", \"to\", \"was\", \"will\", \"with\"]"]},{"cell_type":"markdown","metadata":{"id":"xnq3ujD-0zE0"},"source":["Stripping tags inside <> using regex"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GJ1EN1OM0zE0"},"outputs":[],"source":["def striptags(text: str) -> str:\n","    \"\"\"Removes xml tags.\n","\n","    Args:\n","        text: Text string with xml tags.\n","\n","    Returns:\n","        String without xml tags.\n","    \"\"\"\n","    p = re.compile(r\"<.*?>\")\n","    return p.sub(\"\", text)"]},{"cell_type":"markdown","metadata":{"id":"AR4RMMMP0zE1"},"source":["Parse input text and return a list of indexable terms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cIFWI9Rt0zE2"},"outputs":[],"source":["def parse(text: str) -> List[str]:\n","    \"\"\"Parses documents and removes xml tags and punctuation.\n","\n","    Args:\n","        text: Text to parse.\n","\n","    Returns:\n","        List of tokens.\n","    \"\"\"\n","    terms = []\n","    # Replace specific characters with space\n","    chars = [\"'\", \".\", \":\", \",\", \"!\", \"?\", \"(\", \")\"]\n","    for ch in chars:\n","        text = text.replace(ch, \" \")\n","\n","    # Remove tags\n","    text = striptags(text)\n","\n","    # Tokenization\n","    # default behavior of the split is to split on one or more whitespaces\n","    return [term.lower() for term in text.split() if term not in STOPWORDS]"]},{"cell_type":"markdown","metadata":{"id":"K3QM1JQD0zE3"},"source":["## Processing the input document collection\n","\n","  - The collection is given as a single XML file. \n","  - Each document is inside `<REUTERS ...> </REUTERS>`.\n","  - We extract the contents of the `<DATE>`, `<TITLE>`, and `<BODY>` tags.\n","  - After each extracted document, the provided callback function is called and all document data is passed in a single dict argument."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QD0K0elm0zE3"},"outputs":[],"source":["def process_collection(input_file:str, callback: Callable) -> None:\n","    \"\"\"Processes file and calls the callback function for each document in the\n","    file.\n","\n","    Args:\n","        input_file: Path to file to process.\n","        callback: Function that will be called for each document.\n","    \"\"\"\n","    xmldoc = minidom.parse(input_file)\n","    # Iterate documents in the XML file\n","    itemlist = xmldoc.getElementsByTagName(\"REUTERS\")\n","    for doc_id, doc in enumerate(itemlist):\n","        date = doc.getElementsByTagName(\"DATE\")[0].firstChild.nodeValue\n","        # Skip documents without a title or body\n","        if not (doc.getElementsByTagName(\"TITLE\") and doc.getElementsByTagName(\"BODY\")):\n","            continue\n","        title = doc.getElementsByTagName(\"TITLE\")[0].firstChild.nodeValue\n","        body = doc.getElementsByTagName(\"BODY\")[0].firstChild.nodeValue\n","        callback({\n","            \"doc_id\": doc_id+1,\n","            \"date\": date,\n","            \"title\": title,\n","            \"body\": body\n","            })"]},{"cell_type":"markdown","metadata":{"id":"7fHekO5f0zE4"},"source":["Prints a document\"s contents (used as a callback function passed to `process_collection`)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TeG8m6ZS0zE4"},"outputs":[],"source":["def print_doc(doc: Dict[str, Union[str, int]]) -> None:\n","    \"\"\"Print details of the first 5 documents.\n","\n","    Args:\n","        doc: Dictionary with document details.\n","    \"\"\"\n","    if doc[\"doc_id\"] <= 5:  # print only the first 5 documents\n","        print(\"docID:\", doc[\"doc_id\"])\n","        print(\"date:\", doc[\"date\"])\n","        print(\"title:\", doc[\"title\"])\n","        print(\"body:\", doc[\"body\"])\n","        print(\"--\")"]},{"cell_type":"code","source":["!mkdir data\n","!wget --output-document=\"data/reuters21578-000.xml\" \"https://raw.githubusercontent.com/iai-group/ir-course-2022/main/resources/reuters21578-000.xml\""],"metadata":{"id":"MAtvfGkHyA47"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjRWxXtZ0zE4"},"outputs":[],"source":["process_collection(\"data/reuters21578-000.xml\", print_doc)"]},{"cell_type":"markdown","metadata":{"id":"7N8OHNMT0zE5"},"source":["## Task 1: Complete the inverted index class\n","\n","  - The inverted index is an object with methods for adding and fetching postings.\n","  - The data is stored in a map, where keys are terms and values are lists of postings.\n","  - Each posting is an object that holds the doc_id and an optional payload."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IY-UMYh60zE5"},"outputs":[],"source":["# Since this is a simple data class, intializing it can be abstracted with\n","# the use of dataclass decorator.\n","# https://docs.python.org/3/library/dataclasses.html\n","\n","@dataclass\n","class Posting:\n","    doc_id: int\n","    payload: Any = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yk4YXBzB0zE5"},"outputs":[],"source":["class InvertedIndex:\n","\n","    def __init__(self):\n","        self._index = defaultdict(list)\n","    \n","    def add_posting(self, term: str, doc_id: int, payload: Any=None) -> None:\n","        \"\"\"Adds a document to the posting list of a term.\"\"\"\n","        # append new posting to the posting list\n","        self._index[term].append(Posting(doc_id, payload))\n","\n","    def get_postings(self, term: str) -> List[Posting]:\n","        \"\"\"Fetches the posting list for a given term.\"\"\"\n","        return self._index.get(term)\n","\n","    def get_terms(self) -> List[str]:\n","        \"\"\"Returns all unique terms in the index.\"\"\"\n","        return self._index.keys() \n","    \n","    def write_to_file(self, filename_index: str) -> None:\n","        \"\"\"Saves the index to a textfile.\"\"\"\n","        with open(filename_index, \"w\") as f:\n","            for term, postings in self._index.items():\n","                f.write(term)\n","                for posting in postings:\n","                    f.write(f\" {posting.doc_id}\")\n","                    if posting.payload:\n","                        f.write(f\":{str(posting.payload)}\")\n","                f.write(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"NMmgDSyK0zE5"},"source":["Tests."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l6iG5YzW0zE5"},"outputs":[],"source":["%%run_pytest[clean]\n","\n","def test_postings():\n","    ind = InvertedIndex()\n","    ind.add_posting(\"term\", 1, 1)\n","    ind.add_posting(\"term\", 2, 4)\n","    # Testing existing term\n","    postings = ind.get_postings(\"term\")\n","    assert len(postings) == 2\n","    assert postings[0].doc_id == 1\n","    assert postings[0].payload == 1\n","    assert postings[1].doc_id == 2\n","    assert postings[1].payload == 4\n","    # Testing non-existent term\n","    assert ind.get_postings(\"xyx\") is None\n","\n","def test_vocabulary():\n","    ind = InvertedIndex()\n","    ind.add_posting(\"term1\", 1)\n","    ind.add_posting(\"term2\", 1)\n","    ind.add_posting(\"term3\", 2)\n","    ind.add_posting(\"term2\", 3)\n","    assert set(ind.get_terms()) == set([\"term1\", \"term2\", \"term3\"])"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"2qcqTTxL0zE6"},"source":["## Task 2: Build an inverted index from the input collection\n","\n","**TODO**: Complete the code to index the entire document collection.  (The content for each document should be the title and body concatenated)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bwwoSc8G0zE6"},"outputs":[],"source":["ind = InvertedIndex()\n","\n","def index_doc(doc: Dict[str, Union[str, int]]) -> None:\n","    \"\"\"Index document by concatenating document title and body.\n","\n","    Args:\n","        doc: Document details.\n","    \"\"\"\n","    text = doc[\"title\"] + \" \" + doc[\"body\"]\n","    terms = parse(text)  # list of terms in the document\n","    tc = Counter(terms)  # dict with term counts\n","    for term, freq in tc.items():\n","        ind.add_posting(term, doc[\"doc_id\"], freq)\n","    \n","process_collection(\"data/reuters21578-000.xml\", index_doc)"]},{"cell_type":"markdown","metadata":{"id":"nbDosh_20zE6"},"source":["## Task 3: Save the inverted index to a file"]},{"cell_type":"markdown","metadata":{"id":"qGuVr-Uf0zE6"},"source":["Save the inverted index to a file (`data/index.dat`). Use a simple text format with `termID docID1:freq1 docID2:freq2 ...` per line, e.g.,\n","\n","```\n","xxx 1:1 2:1 3:2\n","yyy 2:1 4:2\n","zzz 1:3 3:1 5:2\n","...\n","```\n","\n","Implement this by (1) adding a `write_to_file(self, filename)` method to the `InvertedIndex` class and then (2) invoking that method in the cell below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ME1Qj5rl0zE7"},"outputs":[],"source":["ind.write_to_file(\"data/index.dat\")"]},{"cell_type":"markdown","metadata":{"id":"GYKS32Iz0zE7"},"source":["## Task 4 (advanced, optional): Plot collection size against index size"]},{"cell_type":"markdown","metadata":{"id":"6HvWcEiK0zE7"},"source":["Create a plot that compares the size of the document collection (bytes) against the size of the corresponding index (bytes) on the y-axis vs. with respect to the number of documents on the x-axis. You may use [Matplotlib](https://www.tutorialspoint.com/jupyter/jupyter_notebook_plotting.htm) for plotting."]},{"cell_type":"markdown","metadata":{"id":"x9_vplhy0zE7"},"source":["In our solution, we create a different callback function and use that one for indexing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0dzpL9070zE7"},"outputs":[],"source":["import sys\n","import os\n","\n","ind = InvertedIndex()\n","tmp_file = \"data/index_tmp.dat\"\n","stats = {\n","    \"i\": 0,\n","    \"sum_bytes\": 0,\n","    \"num_docs\": [],\n","    \"size_index\": [],\n","    \"size_docs\": []\n","}\n","\n","def index_doc_with_stats(doc: Dict[str, Union[str, int]]) -> None:\n","    \"\"\"Indexes documents and updates stats dictionary.\n","\n","    Args:\n","        doc: [description]\n","    \"\"\"\n","    index_doc(doc)\n","    # Stats are stored in a global variable (not very elegant but quick solution)\n","    stats[\"i\"] += 1\n","    stats[\"sum_bytes\"] += sys.getsizeof(str(doc))  # String document representation is a good proxy for doc size\n","    # We measure index size and document collection size after every 100 docs\n","    if stats[\"i\"] % 100 == 0:\n","        stats[\"num_docs\"].append(stats[\"i\"])\n","        stats[\"size_docs\"].append(stats[\"sum_bytes\"])\n","        # To get index size, we dump it to a file and get file size\n","        # Alternatively, the pympler package may be used to measure the size of Python objects\n","        ind.write_to_file(tmp_file)\n","        stats[\"size_index\"].append(os.path.getsize(tmp_file))\n","        \n","process_collection(\"data/reuters21578-000.xml\", index_doc_with_stats)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mAyPt7yD0zE8"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Rendering plots inline in Jupyter notebooks.\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N5FqGWSD0zE8"},"outputs":[],"source":["plt.plot(stats[\"num_docs\"], stats[\"size_docs\"], label=\"Collection size\")\n","plt.plot(stats[\"num_docs\"], stats[\"size_index\"], label=\"Index size\")\n","plt.xlabel(\"Number of documents\")\n","plt.ylabel(\"Bytes\")\n","plt.legend(loc=\"upper left\")\n","plt.show()"]}],"metadata":{"interpreter":{"hash":"d6a0b9ba27f634b55723b9a72ccf6e1561be2239a81593bce53747f2fee7a1a2"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"E3-1-Inverted_index.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}