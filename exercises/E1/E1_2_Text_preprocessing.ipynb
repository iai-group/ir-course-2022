{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jDta06Q5zkD"
      },
      "source": [
        "# Text preprocessing\n",
        "\n",
        "In this exercise, you'll need to implement basic text preprocessing steps."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ipytest"
      ],
      "metadata": {
        "id": "VQXIuPwd55GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPzbGg6A5zkE"
      },
      "outputs": [],
      "source": [
        "from typing import List, Set\n",
        "import ipytest\n",
        "import string\n",
        "import re\n",
        "\n",
        "ipytest.autoconfig()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1atNr1xm5zkF"
      },
      "source": [
        "## Task 1: Tokenization\n",
        "\n",
        "Split an input text into tokens based on whitespaces, punctuation, hyphens, and HTML markup. Additionally, lowercase all tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEVqJ0a-5zkG"
      },
      "outputs": [],
      "source": [
        "def tokenize(text: str)-> List[str]:    \n",
        "    \"\"\"Returns a sequence of terms given an input text.\"\"\"\n",
        "    # Remove HTML markup using a regular expression.\n",
        "    re_html = re.compile(\"<[^>]+>\")\n",
        "    text = re_html.sub(\" \", text)\n",
        "    # Replace punctuation marks (including hyphens) with spaces.\n",
        "    for c in string.punctuation:\n",
        "        text = text.replace(c, \" \")\n",
        "    # Lowercase and split on whitespaces.\n",
        "    return text.lower().split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GQK55Rr5zkG"
      },
      "source": [
        "Tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3C8B-PJ5zkH"
      },
      "outputs": [],
      "source": [
        "%%run_pytest[clean]\n",
        "\n",
        "def test_whitespace():\n",
        "    assert tokenize(\"aaa bbb ccc\") == [\"aaa\", \"bbb\", \"ccc\"]\n",
        "    \n",
        "def test_punctuation():\n",
        "    assert tokenize(\"aaa! bbb.ccc,ddd:eee ff\\\"f\") == [\"aaa\", \"bbb\", \"ccc\", \"ddd\", \"eee\", \"ff\", \"f\"]\n",
        "    \n",
        "def test_hyphens():\n",
        "    assert tokenize(\"aaa bbb-Ccc\") == [\"aaa\", \"bbb\", \"ccc\"]\n",
        "    \n",
        "def test_html():\n",
        "    assert tokenize(\"aaa <bbb>ccc <ddd>eee</ddd></bbb>fff <ggg />\") == [\"aaa\", \"ccc\", \"eee\", \"fff\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DeJ8IXl5zkH"
      },
      "source": [
        "## Task 2: Stopwords removal\n",
        "\n",
        "Remove stopwords from a sequence of tokens, given a set of stopwords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBXz41375zkI"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(tokens: List[str], stopwords: Set[str]) -> List[str]:\n",
        "    \"\"\"Removes stopwords from a sequence of tokens.\"\"\"\n",
        "    return [token for token in tokens if token not in stopwords]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeqR2gNY5zkI"
      },
      "source": [
        "Tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7a-Ideu5zkJ"
      },
      "outputs": [],
      "source": [
        "%%run_pytest[clean]\n",
        "\n",
        "def test_no_stopwords():\n",
        "    assert remove_stopwords([\"this\", \"is\", \"some\", \"text\"], {}) == [\"this\", \"is\", \"some\", \"text\"]\n",
        "    \n",
        "def test_stopwords():\n",
        "    assert remove_stopwords([\"this\", \"is\", \"some\", \"text\"], {\"is\", \"this\"}) == [\"some\", \"text\"]\n",
        "    \n",
        "def test_stopwords2():\n",
        "    assert remove_stopwords([\"this\", \"isolate\", \"otto\"], {\"is\", \"this\", \"to\"}) == [\"isolate\", \"otto\"]    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoQTh3_25zkK"
      },
      "source": [
        "## Task 3: Suffix-s stemming\n",
        "\n",
        "Remove the s-suffix from all terms in a sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wy9zy8y55zkK"
      },
      "outputs": [],
      "source": [
        "def suffix_s_stemmer(terms: List[str]) -> List[str]:\n",
        "    \"\"\"Removes the s-suffix from all terms in a sequence.\"\"\"\n",
        "    stemmed_terms = []\n",
        "    for term in terms:        \n",
        "        stemmed_term = term[:-1] if term[-1] == \"s\" else term\n",
        "        stemmed_terms.append(stemmed_term)\n",
        "    return stemmed_terms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coaaPaHT5zkK"
      },
      "source": [
        "Tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0A-_Iwc5zkK"
      },
      "outputs": [],
      "source": [
        "%%run_pytest[clean]\n",
        "\n",
        "def test_stemming():\n",
        "    assert suffix_s_stemmer([\"dogs\", \"better\", \"cats\"]) == [\"dog\", \"better\", \"cat\"]"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d6a0b9ba27f634b55723b9a72ccf6e1561be2239a81593bce53747f2fee7a1a2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}